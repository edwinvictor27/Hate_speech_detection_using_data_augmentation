{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c538221c-cf7d-4679-821f-dcc74e85fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from symspellpy import SymSpell, Verbosity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9476ee4f-bdd3-47f6-b487-e613fe8f3ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>25291</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>25292</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>25294</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>25295</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>25296</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0               0      3            0                   0        3      2   \n",
       "1               1      3            0                   3        0      1   \n",
       "2               2      3            0                   3        0      1   \n",
       "3               3      3            0                   2        1      1   \n",
       "4               4      6            0                   6        0      1   \n",
       "...           ...    ...          ...                 ...      ...    ...   \n",
       "24778       25291      3            0                   2        1      1   \n",
       "24779       25292      3            0                   1        2      2   \n",
       "24780       25294      3            0                   3        0      1   \n",
       "24781       25295      6            0                   6        0      1   \n",
       "24782       25296      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
       "...                                                  ...  \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
       "24779  you've gone and broke the wrong heart baby, an...  \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...  \n",
       "24781              youu got wild bitches tellin you lies  \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
       "\n",
       "[24783 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"D:\\epita class notes\\semester - 3\\action learnign\\project repository\\Hate_speech_detection_using_data_augmentation\\Hate_speech_detection_using_data_augmentation\\data\\original_dataset\\labeled_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ab91c3-dfe9-48de-b5d3-03dd622b3eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1017</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;#128514;&amp;#128514;&amp;#128514;&amp;#128514; RT @SMASH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1018</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;#128514;&amp;#128514;&amp;#128514;&amp;#128514; bitch if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1019</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;#128514;&amp;#128514;&amp;#128514;&amp;#128514; these fol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1020</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;#128514;&amp;#128514;&amp;#128514;&amp;#128514;&amp;#128514; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1021</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;#128514;&amp;#128514;&amp;#128514;&amp;#128514;&amp;#128514;&amp;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0             0      3            0                   0        3      2   \n",
       "1             1      3            0                   3        0      1   \n",
       "2             2      3            0                   3        0      1   \n",
       "3             3      3            0                   2        1      1   \n",
       "4             4      6            0                   6        0      1   \n",
       "..          ...    ...          ...                 ...      ...    ...   \n",
       "995        1017      3            0                   3        0      1   \n",
       "996        1018      3            0                   3        0      1   \n",
       "997        1019      3            0                   2        1      1   \n",
       "998        1020      6            0                   6        0      1   \n",
       "999        1021      3            1                   2        0      1   \n",
       "\n",
       "                                                 tweet  \n",
       "0    !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1    !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2    !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3    !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4    !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
       "..                                                 ...  \n",
       "995  &#128514;&#128514;&#128514;&#128514; RT @SMASH...  \n",
       "996  &#128514;&#128514;&#128514;&#128514; bitch if ...  \n",
       "997  &#128514;&#128514;&#128514;&#128514; these fol...  \n",
       "998  &#128514;&#128514;&#128514;&#128514;&#128514; ...  \n",
       "999  &#128514;&#128514;&#128514;&#128514;&#128514;&...  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df.head(1000)\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e88e71e3-99ef-4241-8386-63f75fb9e7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower() #converting the tweets to lowercase\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text) #removing url's\n",
    "    text = re.sub(r'@\\w+', '', text)  # removing the username from the tweet\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text) #removing non alpha-numeric character\n",
    "    text = re.sub(r'\\s+', ' ', text) #removing extra space\n",
    "    text = re.sub(r'\\brt\\b', '', text) #removing rt from retweeted tweets\n",
    "    text = re.sub(r'\\b[a-zA-Z]*\\*+[a-zA-Z]*\\b', '[censored]', text) #replacing obscene words with censored\n",
    "    text = text.strip()\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4049a215-ea3f-4dbd-8727-e9d93378dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df, sym_spell):\n",
    "    df['cleaned_tweet'] = df['tweet'].apply(clean_text)\n",
    "    df['corrected_tweet'] = df['cleaned_tweet'].apply(lambda x: correct_spelling(x, sym_spell))\n",
    "    return df[['count','hate_speech', 'offensive_language', 'neither','corrected_tweet', 'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34a5fa84-f66e-45a2-872e-1ab1119284d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_symspell():\n",
    "    sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "    dictionary_path = r\"D:\\epita class notes\\semester - 3\\action learnign\\project repository\\Hate_speech_detection_using_data_augmentation\\Hate_speech_detection_using_data_augmentation\\resources\\frequency_dictionary_en_82_765.txt\"\n",
    "    sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "    return sym_spell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ed2e4cc-8f94-4588-80d0-711593321c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spelling(text, sym_spell):\n",
    "    corrected_words = []\n",
    "    for word in text.split():\n",
    "        suggestions = sym_spell.lookup(word, Verbosity.CLOSEST, max_edit_distance=2)\n",
    "        if suggestions:\n",
    "            corrected_words.append(suggestions[0].term)  \n",
    "        else:\n",
    "            corrected_words.append(word) \n",
    "    return ' '.join(corrected_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d59663cd-9795-488f-9b4c-dd5a54be65e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sym_spell = initialize_symspell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb6e99ea-7a20-4961-8a23-4a94e963330b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edwin victor\\AppData\\Local\\Temp\\ipykernel_17144\\4234741622.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['cleaned_tweet'] = df['tweet'].apply(clean_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     count  hate_speech  offensive_language  neither  \\\n",
      "0        3            0                   0        3   \n",
      "1        3            0                   3        0   \n",
      "2        3            0                   3        0   \n",
      "3        3            0                   2        1   \n",
      "4        6            0                   6        0   \n",
      "..     ...          ...                 ...      ...   \n",
      "995      3            0                   3        0   \n",
      "996      3            0                   3        0   \n",
      "997      3            0                   2        1   \n",
      "998      6            0                   6        0   \n",
      "999      3            1                   2        0   \n",
      "\n",
      "                                       corrected_tweet  class  \n",
      "0    as a woman you shouldn't complain about cleani...      2  \n",
      "1    boy date coldtyga own bad for coffin dat hoe i...      1  \n",
      "2    dawn you ever fuck a bitch and she start to cr...      1  \n",
      "3                               she look like a granny      1  \n",
      "4    they shit you hear about me might be true or i...      1  \n",
      "..                                                 ...    ...  \n",
      "995             munda out here sucking bitches howdhow      1  \n",
      "996  bitch if your they hobbit you need to let me k...      1  \n",
      "997      these folks so bad in just here to talk trash      1  \n",
      "998                        brittany bitch a my dog man      1  \n",
      "999                          sch bitch selling her ass      1  \n",
      "\n",
      "[1000 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edwin victor\\AppData\\Local\\Temp\\ipykernel_17144\\4234741622.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['corrected_tweet'] = df['cleaned_tweet'].apply(lambda x: correct_spelling(x, sym_spell))\n"
     ]
    }
   ],
   "source": [
    "cleaned_df_1 = clean_dataset(df_filtered, sym_spell)\n",
    "file_name = \"labeled_data_cleaned.csv\"\n",
    "output_path = r\"D:\\epita class notes\\semester - 3\\action learnign\\project repository\\Hate_speech_detection_using_data_augmentation\\Hate_speech_detection_using_data_augmentation\\data\\cleaned_dataset\"\n",
    "output_file = os.path.join(output_path, file_name)\n",
    "cleaned_df_1.to_csv(output_file, index=False)\n",
    "print(cleaned_df_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b031db30-4b7b-4f3b-9ea3-2da871ddf584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
