{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5f63b84-f817-4b97-af87-cedc6bdafd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer \n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1c8da84-1c3a-4fdd-9366-dbce4d02bfd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>corrected_tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>as a woman you shouldn't complain about cleani...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>boy date coldtyga own bad for coffin dat hoe i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>dawn you ever fuck a bitch and she start to cr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>she look like a granny</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>they shit you hear about me might be true or i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>munda out here sucking bitches howdhow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bitch if your they hobbit you need to let me k...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>these folks so bad in just here to talk trash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>brittany bitch a my dog man</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>sch bitch selling her ass</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     count  hate_speech  offensive_language  neither  \\\n",
       "0        3            0                   0        3   \n",
       "1        3            0                   3        0   \n",
       "2        3            0                   3        0   \n",
       "3        3            0                   2        1   \n",
       "4        6            0                   6        0   \n",
       "..     ...          ...                 ...      ...   \n",
       "995      3            0                   3        0   \n",
       "996      3            0                   3        0   \n",
       "997      3            0                   2        1   \n",
       "998      6            0                   6        0   \n",
       "999      3            1                   2        0   \n",
       "\n",
       "                                       corrected_tweet  class  \n",
       "0    as a woman you shouldn't complain about cleani...      2  \n",
       "1    boy date coldtyga own bad for coffin dat hoe i...      1  \n",
       "2    dawn you ever fuck a bitch and she start to cr...      1  \n",
       "3                               she look like a granny      1  \n",
       "4    they shit you hear about me might be true or i...      1  \n",
       "..                                                 ...    ...  \n",
       "995             munda out here sucking bitches howdhow      1  \n",
       "996  bitch if your they hobbit you need to let me k...      1  \n",
       "997      these folks so bad in just here to talk trash      1  \n",
       "998                        brittany bitch a my dog man      1  \n",
       "999                          sch bitch selling her ass      1  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"D:\\epita class notes\\semester - 3\\action learnign\\project repository\\Hate_speech_detection_using_data_augmentation\\Hate_speech_detection_using_data_augmentation\\data\\cleaned_dataset\\labeled_data_cleaned.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4419ef37-59fc-462d-b812-c317668db2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0      as a woman you shouldn't complain about cleani...\n",
       " 1      boy date coldtyga own bad for coffin dat hoe i...\n",
       " 2      dawn you ever fuck a bitch and she start to cr...\n",
       " 3                                 she look like a granny\n",
       " 4      they shit you hear about me might be true or i...\n",
       "                              ...                        \n",
       " 995               munda out here sucking bitches howdhow\n",
       " 996    bitch if your they hobbit you need to let me k...\n",
       " 997        these folks so bad in just here to talk trash\n",
       " 998                          brittany bitch a my dog man\n",
       " 999                            sch bitch selling her ass\n",
       " Name: corrected_tweet, Length: 1000, dtype: object,\n",
       " 0      2\n",
       " 1      1\n",
       " 2      1\n",
       " 3      1\n",
       " 4      1\n",
       "       ..\n",
       " 995    1\n",
       " 996    1\n",
       " 997    1\n",
       " 998    1\n",
       " 999    1\n",
       " Name: class, Length: 1000, dtype: int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = df['corrected_tweet']\n",
    "label = df['class']\n",
    "texts, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0a7dfc9-6666-497e-bf15-1841de9dcca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_label, val_label = train_test_split(texts, label, test_size=0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43db7f3e-cf38-4ebc-813f-d042482c16d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda\\miniconda\\envs\\action_learning\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97130b45-247e-4b16-b9d9-52291e89e4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(texts, labels):\n",
    "    inputs = tokenizer(list(texts), truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "    inputs['labels'] = torch.tensor(labels.values)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4f2dea2-b5d3-4de4-8e85-e2170a5e9171",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = tokenize_data(train_texts, train_label)\n",
    "val_inputs = tokenize_data(val_texts, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afed5492-ccac-4792-aa3b-040660962d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda\\miniconda\\envs\\action_learning\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e425fc9d-c6bd-4c88-a573-e873639c21d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "351c9b8f-dc19-4f73-b374-8677055b8e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0d39a21-2381-4d48-b4b0-ba18d58a04c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    betas: (0.9, 0.999)\n",
       "    correct_bias: True\n",
       "    eps: 1e-06\n",
       "    lr: 0.01\n",
       "    weight_decay: 0.0\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=0.01)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9fd7071-cd72-4200-a746-2eab0f54269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_inputs, epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = {key: val.to(device) for key, val in train_inputs.items()}\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb7b731c-2fa5-448d-8675-a4d59fefdd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_inputs):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = {key: val.to(device) for key, val in val_inputs.items()}\n",
    "        outputs = model(**inputs)\n",
    "        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "        accuracy = accuracy_score(val_inputs['labels'].cpu().numpy(), preds)\n",
    "        print(f\"Validation Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb05e721-3c3f-464d-8af3-4fe41ec92218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 1.2239773273468018\n",
      "Epoch 2/3, Loss: 1.9949935674667358\n",
      "Epoch 3/3, Loss: 13.615461349487305\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842f413b-05de-4cde-9702-75bd53e4609f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
